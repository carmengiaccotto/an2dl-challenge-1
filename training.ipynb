{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c1c42806ccd7bc",
   "metadata": {
    "id": "c8c1c42806ccd7bc"
   },
   "source": [
    "# **Pirate Pain Challenge - Hyperparameters Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47a74d0babd730",
   "metadata": {
    "id": "bf47a74d0babd730"
   },
   "source": [
    "## ðŸŒ **Google Drive Connection or local mount**"
   ]
  },
  {
   "cell_type": "code",
   "id": "f644bab597852f40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f644bab597852f40",
    "outputId": "8b184930-243e-45a3-c73e-8b8961375221"
   },
   "source": [
    "import os\n",
    "\n",
    "isColab = False\n",
    "isKaggle = False\n",
    "\n",
    "# Directory di default\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "try:\n",
    "    if not isColab:\n",
    "        raise ImportError(\"We are not in google colab\")\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/gdrive\")\n",
    "    current_dir = \"/gdrive/My\\\\ Drive/[2025-2026]\\\\ AN2DL/AN2DL-challenge-1/\"\n",
    "    print(\"In esecuzione su Colab. Google Drive montato.\")\n",
    "    %cd $current_dir\n",
    "    isColab = True\n",
    "\n",
    "except ImportError:\n",
    "    # Rilevamento ambiente Kaggle\n",
    "    if os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") or os.path.exists(\"/kaggle/working\") or isKaggle:\n",
    "        isKaggle = True\n",
    "        kaggle_work_dir = \"/kaggle/working/AN2DL-challenge-1\"\n",
    "        os.makedirs(kaggle_work_dir, exist_ok=True)\n",
    "        current_dir = kaggle_work_dir\n",
    "        print(\"In esecuzione su Kaggle. Directory di lavoro impostata.\")\n",
    "    else:\n",
    "        isColab = False\n",
    "        isKaggle = False\n",
    "        print(\"Esecuzione locale. Salto mount Google Drive.\")\n",
    "        local_pref = r\"G:\\Il mio Drive\\Colab Notebooks\\[2025-2026] AN2DL\\AN2DL-challenge-1\"\n",
    "        current_dir = local_pref if os.path.isdir(local_pref) else os.getcwd()\n",
    "        print(f\"Directory corrente impostata a: {current_dir}\")\n",
    "\n",
    "# Cambio directory se non Colab (su Colab Ã¨ giÃ  fatto con %cd)\n",
    "if not isColab:\n",
    "    os.chdir(current_dir)\n",
    "\n",
    "print(f\"Changed directory to: {current_dir}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "932cdb46ae272e67",
   "metadata": {
    "id": "932cdb46ae272e67"
   },
   "source": [
    "## âš™ï¸ **Libraries Import**"
   ]
  },
  {
   "cell_type": "code",
   "id": "9b8748f0d28fed8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b8748f0d28fed8d",
    "outputId": "6d618f4e-6b90-44c3-8c4c-55fe5d2d489d"
   },
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# Import necessary modules\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for random number generators in NumPy and Python\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "# from torchsummary import summary\n",
    "\n",
    "logs_dir = \"tensorboard\"\n",
    "if isColab:\n",
    "    !pkill -f tensorboard\n",
    "else:\n",
    "    # Arresta eventuali processi tensorboard in locale (Windows)\n",
    "    import os\n",
    "\n",
    "    if os.name == 'nt':\n",
    "        try:\n",
    "            import psutil\n",
    "\n",
    "            for proc in psutil.process_iter(['name', 'cmdline']):\n",
    "                name = (proc.info.get('name') or '').lower()\n",
    "                cmd = ' '.join(proc.info.get('cmdline') or []).lower()\n",
    "                if 'tensorboard' in name or 'tensorboard' in cmd:\n",
    "                    try:\n",
    "                        proc.kill()\n",
    "                    except Exception:\n",
    "                        pass\n",
    "        except ImportError:\n",
    "            import subprocess\n",
    "\n",
    "            subprocess.run(['taskkill', '/F', '/IM', 'tensorboard.exe'],\n",
    "                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "%load_ext tensorboard\n",
    "if isColab:\n",
    "    !mkdir -p models\n",
    "else:\n",
    "    os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Import other libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set_theme(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a8701093d38441af",
   "metadata": {
    "id": "a8701093d38441af"
   },
   "source": [
    "## â³ **Data Downloading**"
   ]
  },
  {
   "cell_type": "code",
   "id": "1191d5d6f484df56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1191d5d6f484df56",
    "outputId": "d6482cae-e372-4335-8fbd-873ee94d162b"
   },
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# --- 1. Impostazioni ---\n",
    "competition_name = 'an2dl2526c1'\n",
    "dataset_path = 'dataset'\n",
    "if isKaggle:\n",
    "    dataset_path = '/kaggle/input/pirate-pain/dataset'\n",
    "train_file = 'pirate_pain_train.csv'\n",
    "test_file = 'pirate_pain_test.csv'\n",
    "labels_file = 'pirate_pain_train_labels.csv'\n",
    "sample_submission_file = 'sample_submission.csv'\n",
    "\n",
    "# Controlla se il dataset Ã¨ giÃ  stato scaricato ed estratto\n",
    "if not isKaggle and not isColab and not os.path.exists(os.path.join(dataset_path, train_file)):\n",
    "    # --- 2. Autenticazione e Download ---\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "    # Inizializza l'API di Kaggle\n",
    "    # L'autenticazione avviene automaticamente se 'kaggle.json' Ã¨ in C:\\\\Users\\\\Bert0ns\\\\.kaggle\\\\\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "\n",
    "    print(f\"Download del dataset dalla competizione '{competition_name}'...\")\n",
    "\n",
    "    # Crea la directory di destinazione se non esiste\n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "    # Scarica i file della competizione nella cartella 'dataset'\n",
    "    api.competition_download_files(competition_name, path=dataset_path)\n",
    "\n",
    "    # Estrai i file dall'archivio zip\n",
    "    zip_path = os.path.join(dataset_path, f'{competition_name}.zip')\n",
    "    if os.path.exists(zip_path):\n",
    "        print(f\"Estrazione dei file da '{zip_path}'...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(dataset_path)\n",
    "        # Rimuovi il file zip dopo l'estrazione\n",
    "        os.remove(zip_path)\n",
    "        print(\"Estrazione completata e file zip rimosso.\")\n",
    "    else:\n",
    "        print(\"ATTENZIONE: File zip non trovato. Il download potrebbe non essere riuscito.\")\n",
    "else:\n",
    "    print(f\"Il dataset Ã¨ giÃ  presente nella cartella {dataset_path}. Download saltato.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f0189d20bfdbdbfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T09:59:15.146847Z",
     "start_time": "2025-11-08T09:59:15.142723Z"
    },
    "id": "f0189d20bfdbdbfc"
   },
   "source": [
    "## ðŸ”Ž **Exploration and Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "id": "9d0c6a84418bf8a0",
   "metadata": {
    "id": "9d0c6a84418bf8a0"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "if not isColab:\n",
    "    dataset_df = pd.read_csv(os.path.join(dataset_path, train_file))\n",
    "    kaggle_test_df = pd.read_csv(os.path.join(dataset_path, test_file))\n",
    "    labels_df = pd.read_csv(os.path.join(dataset_path, labels_file))\n",
    "else:\n",
    "    dataset_df = pd.read_csv(dataset_path + '/pirate_pain_train.csv')\n",
    "    kaggle_test_df = pd.read_csv(dataset_path + '/pirate_pain_test.csv')\n",
    "    labels_df = pd.read_csv(dataset_path + '/pirate_pain_train_labels.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ab93bdf2d91e1a31",
   "metadata": {
    "id": "ab93bdf2d91e1a31"
   },
   "source": [
    "**Convert data to a memory efficient form**"
   ]
  },
  {
   "cell_type": "code",
   "id": "806aabad03a2142f",
   "metadata": {
    "id": "806aabad03a2142f"
   },
   "source": [
    "\n",
    "text_map = {\n",
    "    'two': 0,\n",
    "    'one+peg_leg': 1, 'one+hook_hand': 2, 'one+eye_patch': 3,\n",
    "}\n",
    "\n",
    "# Pulisce, normalizza, mappa; fallback a numerico e a cifre estratte\n",
    "columns_to_convert = ['n_legs', 'n_hands', 'n_eyes']\n",
    "for col in columns_to_convert:\n",
    "    dataset_df[col] = dataset_df[col].str.strip().str.lower().map(text_map).astype('int8')\n",
    "    kaggle_test_df[col] = kaggle_test_df[col].str.strip().str.lower().map(text_map).astype('int8')\n",
    "\n",
    "# train_df.head(105760)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0e83165934c5ead",
   "metadata": {
    "id": "c0e83165934c5ead"
   },
   "source": [
    "# Convert data types from float64 to float32 to save memory\n",
    "dataset_df[dataset_df.select_dtypes(include=['float64']).columns] = dataset_df.select_dtypes(\n",
    "    include=['float64']).astype(\n",
    "    'float32')\n",
    "kaggle_test_df[kaggle_test_df.select_dtypes(include=['float64']).columns] = kaggle_test_df.select_dtypes(\n",
    "    include=['float64']).astype(\n",
    "    'float32')\n",
    "\n",
    "# Convert int64 to int32\n",
    "dataset_df[dataset_df.select_dtypes(include=['int64']).columns] = dataset_df.select_dtypes(include=['int64']).astype(\n",
    "    'int32')\n",
    "kaggle_test_df[kaggle_test_df.select_dtypes(include=['int64']).columns] = kaggle_test_df.select_dtypes(\n",
    "    include=['int64']).astype('int32')\n",
    "labels_df[labels_df.select_dtypes(include=['int64']).columns] = labels_df.select_dtypes(include=['int64']).astype(\n",
    "    'int32')\n",
    "\n",
    "# Convert pain surveys to int8\n",
    "dataset_df['pain_survey_1'] = dataset_df['pain_survey_1'].astype('int8')\n",
    "dataset_df['pain_survey_2'] = dataset_df['pain_survey_2'].astype('int8')\n",
    "dataset_df['pain_survey_3'] = dataset_df['pain_survey_3'].astype('int8')\n",
    "dataset_df['pain_survey_4'] = dataset_df['pain_survey_4'].astype('int8')\n",
    "\n",
    "kaggle_test_df['pain_survey_1'] = kaggle_test_df['pain_survey_1'].astype('int8')\n",
    "kaggle_test_df['pain_survey_2'] = kaggle_test_df['pain_survey_2'].astype('int8')\n",
    "kaggle_test_df['pain_survey_3'] = kaggle_test_df['pain_survey_3'].astype('int8')\n",
    "kaggle_test_df['pain_survey_4'] = kaggle_test_df['pain_survey_4'].astype('int8')\n",
    "\n",
    "# Convert labels sample_index to int8\n",
    "label_map = {'low_pain': 1, 'no_pain': 0, 'high_pain': 2}\n",
    "\n",
    "labels_df['label'] = labels_df['label'].str.strip().str.lower().map(label_map).astype('int8')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Prepare the Time feature**",
   "id": "dfb49b2077a3e588"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# --- Time features: normalized_time + sin/cos ---\n",
    "TIME_FEATURES = ['time_norm', 'time_sin', 'time_cos']\n",
    "# Vengono aggiunte tre nuove colonne continue: time_norm, time_sin, time_cos\n",
    "# Se la sequenza per un sample ha lunghezza variabile, normalizziamo dividendo per il max time per sample.\n",
    "for _df in [dataset_df, kaggle_test_df]:\n",
    "    if 'time' in _df.columns and 'time_norm' not in _df.columns:\n",
    "        max_time = _df.groupby('sample_index')['time'].transform('max').replace(0, 1)\n",
    "        _df['time_norm'] = (_df['time'] / max_time).astype('float32')\n",
    "        _df['time_sin'] = np.sin(2 * np.pi * _df['time_norm']).astype('float32')\n",
    "        _df['time_cos'] = np.cos(2 * np.pi * _df['time_norm']).astype('float32')\n",
    "\n",
    "TIME_FEATURES = []"
   ],
   "id": "2d75f4faaf0be3ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset_df.head(2000)",
   "id": "8f55c87c65e40012",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3f43311eda52cde4",
   "metadata": {
    "id": "3f43311eda52cde4"
   },
   "source": [
    "## ðŸ”„ **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "id": "d4a62dc6b39e0396",
   "metadata": {
    "id": "d4a62dc6b39e0396"
   },
   "source": [
    "VALIDATION_SET_PERCENTAGE = 0.2\n",
    "TEST_SET_PERCENTAGE = 0.2\n",
    "\n",
    "MAX_N_STD_DEVIATION = 5  # Clipping threshold for outliers, number of standard deviations from the mean\n",
    "\n",
    "JOINT_COLUMNS = [f'joint_{i:02d}' for i in range(31)]\n",
    "\n",
    "CONTINUOUS_COLS = JOINT_COLUMNS + TIME_FEATURES\n",
    "CATEGORICAL_COLS = ['n_legs', 'n_hands', 'n_eyes', 'pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4']\n",
    "\n",
    "COLUMNS_TO_REMOVE = ['joint_30', 'n_legs', 'n_hands', 'joint_24']\n",
    "\n",
    "COLS_TO_EXCLUDE_FROM_NORMALIZATION = TIME_FEATURES"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "295ac2b85394b9c",
   "metadata": {
    "id": "295ac2b85394b9c"
   },
   "source": [
    "num_classes = len(labels_df['label'].unique())\n",
    "unique_samples = dataset_df['sample_index'].unique()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "add7800109f02509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:06:02.823302Z",
     "start_time": "2025-11-08T10:06:02.818073Z"
    },
    "id": "add7800109f02509"
   },
   "source": [
    "#### Remove useless features"
   ]
  },
  {
   "cell_type": "code",
   "id": "4a85d49564acf7ed",
   "metadata": {
    "id": "4a85d49564acf7ed"
   },
   "source": [
    "# @title Remove feature from joint_13 to joint_25 + joint_30\n",
    "df_dataset_reduced = dataset_df.drop(columns=COLUMNS_TO_REMOVE, inplace=False)\n",
    "kaggle_test_df_reduced = kaggle_test_df.drop(columns=COLUMNS_TO_REMOVE, inplace=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a75b6bdd01a5f9d4",
   "metadata": {
    "id": "a75b6bdd01a5f9d4"
   },
   "source": [
    "# Rimuoviamo le colonne eliminate anche dalle nostre liste di colonne\n",
    "CONTINUOUS_COLS_REDUCED = [col for col in CONTINUOUS_COLS if col not in COLUMNS_TO_REMOVE]\n",
    "CATEGORICAL_COLS_REDUCED = [col for col in CATEGORICAL_COLS if col not in COLUMNS_TO_REMOVE]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **PCA on joints**",
   "id": "5cc26c2e23853e3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.96, random_state=SEED)\n",
    "pca_features = pca.fit_transform(df_dataset_reduced[CONTINUOUS_COLS_REDUCED])\n",
    "\n",
    "# Rimuovi le colonne originali e aggiungi le componenti PCA\n",
    "df_dataset_reduced = df_dataset_reduced.drop(columns=CONTINUOUS_COLS_REDUCED)\n",
    "pca_columns = [f'pca_{i:02d}' for i in range(pca_features.shape[1])]\n",
    "df_dataset_reduced[pca_columns] = pca_features\n",
    "\n",
    "# Applica la stessa trasformazione PCA al test set di Kaggle\n",
    "kaggle_test_pca = pca.transform(kaggle_test_df_reduced[CONTINUOUS_COLS_REDUCED])\n",
    "kaggle_test_df_reduced = kaggle_test_df_reduced.drop(columns=CONTINUOUS_COLS_REDUCED)\n",
    "kaggle_test_df_reduced[pca_columns] = kaggle_test_pca\n",
    "\n",
    "# Aggiorna la lista delle colonne continue\n",
    "CONTINUOUS_COLS_REDUCED = pca_columns\n",
    "\n",
    "df_dataset_reduced.head(1000)"
   ],
   "id": "4c5da1794c160066",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **Clipping data to mitigate outliers**",
   "id": "89ba09fc1881c64b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clip_by_std(df, cols, k=4):\n",
    "    for c in cols:\n",
    "        m = df[c].mean()\n",
    "        s = df[c].std()\n",
    "        lo, hi = m - k * s, m + k * s\n",
    "        df[c] = df[c].clip(lo, hi)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_dataset_reduced = clip_by_std(\n",
    "    df_dataset_reduced,\n",
    "    cols=CONTINUOUS_COLS_REDUCED,\n",
    "    k=MAX_N_STD_DEVIATION\n",
    ")\n",
    "kaggle_test_df_reduced = clip_by_std(\n",
    "    kaggle_test_df_reduced,\n",
    "    cols=CONTINUOUS_COLS_REDUCED,\n",
    "    k=MAX_N_STD_DEVIATION\n",
    ")\n"
   ],
   "id": "c561e8499c77f2e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Build sequences with sliding window\n",
    "\n",
    "ðŸŽ¯ **Adaptive Padding Strategy**\n",
    "\n",
    "Invece di usare padding con zeri (che introduce rumore), usiamo **padding adattivo**:\n",
    "- **Continuous features**: Usa la media dell'ultimo N timesteps della sequenza\n",
    "- **Categorical features**: Usa la moda (valore piÃ¹ frequente) dell'ultimo N timesteps\n",
    "- **Fallback**: Se necessario, usa le statistiche globali del dataset\n",
    "\n",
    "Questo approccio riduce il rumore e migliora la qualitÃ  delle predizioni."
   ],
   "id": "7a9bfb04ec7a1aee"
  },
  {
   "cell_type": "code",
   "id": "9de97e0a807adc2a",
   "metadata": {
    "id": "9de97e0a807adc2a"
   },
   "source": [
    "\n",
    "def build_sequences(df, label_df, continuous_cols, categorical_cols, window=200, stride=200,\n",
    "                    padding_strategy='adaptive', lookback_steps=10):\n",
    "    \"\"\"\n",
    "    Build sequences from time series data with intelligent padding.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with time series data\n",
    "        label_df: DataFrame with labels\n",
    "        continuous_cols: List of continuous feature columns\n",
    "        categorical_cols: List of categorical feature columns\n",
    "        window: Window size for sequences\n",
    "        stride: Stride for sliding window\n",
    "        padding_strategy: 'adaptive' (mean/mode), 'repeat' (repeat last), or 'zero' (zeros)\n",
    "        lookback_steps: Number of timesteps to use for computing padding statistics\n",
    "\n",
    "    Returns:\n",
    "        dataset_continuous, dataset_categorical, labels\n",
    "    \"\"\"\n",
    "    dataset_continuous = []\n",
    "    dataset_categorical = []\n",
    "    labels = []\n",
    "\n",
    "    # Pre-compute global statistics for fallback (only if adaptive)\n",
    "    if padding_strategy == 'adaptive':\n",
    "        global_cont_mean = df[continuous_cols].mean().values.astype('float32')\n",
    "        global_cat_mode = df[categorical_cols].mode().iloc[0].values.astype('int8')\n",
    "\n",
    "    for sample_id in df['sample_index'].unique():\n",
    "        # Extract data for current sample\n",
    "        temp_continuous = df[df['sample_index'] == sample_id][continuous_cols].values\n",
    "        temp_categorical = df[df['sample_index'] == sample_id][categorical_cols].values\n",
    "\n",
    "        label = label_df[label_df['sample_index'] == sample_id]['label'].values[0]\n",
    "\n",
    "        # Calculate padding length\n",
    "        padding_len = (window - len(temp_continuous) % window) % window\n",
    "\n",
    "        if padding_strategy == 'adaptive':\n",
    "            # Adaptive padding: use statistics from last N timesteps\n",
    "            lookback = min(lookback_steps, len(temp_continuous))\n",
    "\n",
    "            if lookback > 0:\n",
    "                # Use mean of last timesteps for continuous\n",
    "                last_cont_values = temp_continuous[-lookback:]\n",
    "                pad_cont_value = np.mean(last_cont_values, axis=0, keepdims=True)\n",
    "\n",
    "                # Use mode of last timesteps for categorical\n",
    "                last_cat_values = temp_categorical[-lookback:]\n",
    "                pad_cat_value = np.array([\n",
    "                    np.bincount(last_cat_values[:, i]).argmax()\n",
    "                    for i in range(last_cat_values.shape[1])\n",
    "                ]).reshape(1, -1)\n",
    "            else:\n",
    "                # Fallback to global statistics\n",
    "                pad_cont_value = global_cont_mean.reshape(1, -1)\n",
    "                pad_cat_value = global_cat_mode.reshape(1, -1)\n",
    "\n",
    "            # Create padding by repeating the computed values\n",
    "            padding_cont = np.repeat(pad_cont_value, padding_len, axis=0).astype('float32')\n",
    "            padding_cat = np.repeat(pad_cat_value, padding_len, axis=0).astype('int8')\n",
    "        elif padding_strategy == 'repeat':\n",
    "            # Repeat last timestep\n",
    "            if len(temp_continuous) > 0:\n",
    "                padding_cont = np.repeat(temp_continuous[-1:], padding_len, axis=0)\n",
    "                padding_cat = np.repeat(temp_categorical[-1:], padding_len, axis=0)\n",
    "            else:\n",
    "                # Fallback to zeros if no data\n",
    "                padding_cont = np.zeros((padding_len, temp_continuous.shape[1]), dtype='float32')\n",
    "                padding_cat = np.zeros((padding_len, temp_categorical.shape[1]), dtype='int8')\n",
    "        else:  # 'zero' or default\n",
    "            # Original zero padding\n",
    "            padding_cont = np.zeros((padding_len, temp_continuous.shape[1]), dtype='float32')\n",
    "            padding_cat = np.zeros((padding_len, temp_categorical.shape[1]), dtype='int8')\n",
    "\n",
    "        temp_continuous = np.concatenate((temp_continuous, padding_cont))\n",
    "        temp_categorical = np.concatenate((temp_categorical, padding_cat))\n",
    "\n",
    "        # Build windows with sliding stride\n",
    "        idx = 0\n",
    "        while idx + window <= len(temp_continuous):\n",
    "            dataset_continuous.append(temp_continuous[idx:idx + window])\n",
    "            dataset_categorical.append(temp_categorical[idx:idx + window])\n",
    "            labels.append(label)\n",
    "            idx += stride\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    dataset_continuous = np.array(dataset_continuous, dtype='float32')\n",
    "    dataset_categorical = np.array(dataset_categorical, dtype='int8')\n",
    "    labels = np.array(labels, dtype='int64')\n",
    "\n",
    "    return dataset_continuous, dataset_categorical, labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed8af00de3bc02e6",
   "metadata": {
    "id": "ed8af00de3bc02e6"
   },
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "def make_loader(ds, batch_size, shuffle, drop_last):\n",
    "    # Determine optimal number of worker processes for data loading\n",
    "    cpu_cores = os.cpu_count() or 2\n",
    "    num_workers = max(2, min(4, cpu_cores))\n",
    "\n",
    "    # Create DataLoader with performance optimizations\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,  # Faster GPU transfer\n",
    "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
    "        prefetch_factor=4,  # Load 4 batches ahead\n",
    "        persistent_workers=True if num_workers > 0 else False,  # Mantiene i worker attivi\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "484246425afe5f5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:30:46.123364Z",
     "start_time": "2025-11-08T10:30:46.113836Z"
    },
    "id": "484246425afe5f5f"
   },
   "source": [
    "## ðŸ› ï¸ **Model Building**"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def cross_attention(Q, K, V, mask=None):\n",
    "    # Compute the dot products between Q and K, then scale\n",
    "    d_k = Q.size(-1)\n",
    "    scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "\n",
    "    # Apply mask if provided\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "    # Softmax to normalize scores and get attention weights\n",
    "    attention_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "    # Weighted sum of values\n",
    "    output = torch.matmul(attention_weights, V)\n",
    "    return output, attention_weights"
   ],
   "id": "e879411f4b385c0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class CustomAttention(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads=1, attention_type=\"self\"):\n",
    "        super(CustomAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_type = attention_type\n",
    "\n",
    "        # Linear layers for Q, K, V\n",
    "        self.query = nn.Linear(embed_size, embed_size)\n",
    "        self.key = nn.Linear(embed_size, embed_size)\n",
    "        self.value = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "        # Final linear layer after concatenating heads (qui num_heads=1)\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, target, source=None, mask=None):\n",
    "        \"\"\"Self- o cross-attention su tensori 3D (batch, seq_len, embed_size).\n",
    "\n",
    "        - target: (B, T, D)\n",
    "        - source: (B, T_src, D) se attention_type == \"cross\"\n",
    "        - output: (B, T, D)\n",
    "        \"\"\"\n",
    "        if self.attention_type == \"self\":\n",
    "            Q = self.query(target)\n",
    "            K = self.key(target)\n",
    "            V = self.value(target)\n",
    "        elif self.attention_type == \"cross\":\n",
    "            assert source is not None, \"Source input required for cross-attention\"\n",
    "            Q = self.query(target)\n",
    "            K = self.key(source)\n",
    "            V = self.value(source)\n",
    "        else:\n",
    "            raise ValueError(\"attention_type must be 'self' or 'cross'\")\n",
    "\n",
    "        # Esegui l'attenzione (il training loop gestisce giÃ  autocast/mixed precision)\n",
    "        output, attention_weights = cross_attention(Q, K, V, mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "\n",
    "class CustomAttentionWithResidual(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads=1, attention_type=\"self\"):\n",
    "        super(CustomAttentionWithResidual, self).__init__()\n",
    "        self.attention = CustomAttention(embed_size, num_heads, attention_type)\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, target, source=None, mask=None):\n",
    "        \"\"\"Blocchetto tipo Transformer: attention + residual + layer norm.\n",
    "\n",
    "        - target: (B, T, D)\n",
    "        - output: (B, T, D) stessa shape\n",
    "        \"\"\"\n",
    "        attention_out = self.attention(target, source, mask)\n",
    "        out = self.norm(target + self.dropout(attention_out))\n",
    "        return out"
   ],
   "id": "13ac852bbffcbfe5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e391dae3456274e",
   "metadata": {
    "id": "6e391dae3456274e"
   },
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "class RecurrentClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Generic RNN classifier with Embedding layer for categorical features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            continuous_input_size,\n",
    "            categorical_cardinalities,\n",
    "            embedding_dims,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            num_classes,\n",
    "            rnn_type='GRU',\n",
    "            bidirectional=False,\n",
    "            dropout_rate=0.2,\n",
    "            rnn_inside_dropout: float = 0.0,\n",
    "            use_conv: bool = False,\n",
    "            conv_num_filters: int = 64,\n",
    "            conv_kernel_size: int = 5,\n",
    "            conv_num_layers: int = 1,\n",
    "            conv_stride: int = 1,\n",
    "            conv_pool: Optional[int] = None,\n",
    "            conv_batch_norm: bool = True,\n",
    "            use_attention: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.use_conv = use_conv\n",
    "        self.conv_num_layers = conv_num_layers\n",
    "        self.conv_kernel_size = conv_kernel_size\n",
    "        self.conv_num_filters = conv_num_filters\n",
    "\n",
    "        self.use_attention = use_attention\n",
    "\n",
    "        # 1. Embedding Layers per le feature categoriche\n",
    "        self.embedding_layers = nn.ModuleList([\n",
    "            nn.Embedding(num_embeddings, emb_dim)\n",
    "            for num_embeddings, emb_dim in zip(categorical_cardinalities, embedding_dims)\n",
    "        ])\n",
    "        total_embedding_dim = sum(embedding_dims)\n",
    "\n",
    "        # 2. Calcola la dimensione dell'input per la RNN\n",
    "        rnn_input_size = continuous_input_size + total_embedding_dim\n",
    "\n",
    "        rnn_map = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}\n",
    "        if rnn_type not in rnn_map:\n",
    "            raise ValueError(\"rnn_type must be 'RNN', 'LSTM', or 'GRU'\")\n",
    "        rnn_module = rnn_map[rnn_type]\n",
    "\n",
    "        # Dropout interno alla RNN: applicato solo se num_layers > 1\n",
    "        dropout_val = rnn_inside_dropout if num_layers > 1 else 0.0\n",
    "\n",
    "        if use_conv:\n",
    "            conv_layers = []\n",
    "            in_channels = rnn_input_size\n",
    "            for layer_idx in range(conv_num_layers):\n",
    "                out_channels = conv_num_filters\n",
    "                conv_layers.append(\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=in_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        kernel_size=conv_kernel_size,\n",
    "                        stride=conv_stride,\n",
    "                        padding=(conv_kernel_size - 1) // 2,\n",
    "                        padding_mode='zeros',\n",
    "                    )\n",
    "                )\n",
    "                if conv_batch_norm:\n",
    "                    conv_layers.append(nn.BatchNorm1d(out_channels))\n",
    "                conv_layers.append(nn.ReLU())\n",
    "                if conv_pool:\n",
    "                    conv_layers.append(nn.MaxPool1d(kernel_size=conv_pool, stride=conv_pool))\n",
    "                in_channels = out_channels\n",
    "            self.conv_block = nn.Sequential(*conv_layers)\n",
    "            rnn_input_size = in_channels\n",
    "\n",
    "        # Dropout espliciti esterni\n",
    "        self.pre_rnn_dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.post_rnn_dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        # 3. Crea il layer ricorrente\n",
    "        self.rnn = rnn_module(\n",
    "            input_size=rnn_input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout_val\n",
    "        )\n",
    "\n",
    "        rnn_output_dim = hidden_size * 2 if self.bidirectional else hidden_size\n",
    "\n",
    "        # Inizializza attention solo se abilitata\n",
    "        if self.use_attention:\n",
    "            self.attention = CustomAttentionWithResidual(\n",
    "                embed_size=rnn_output_dim,\n",
    "                num_heads=1,\n",
    "                attention_type=\"self\"\n",
    "            )\n",
    "        else:\n",
    "            self.attention = None\n",
    "\n",
    "        self.classifier = nn.Linear(rnn_output_dim, num_classes)\n",
    "\n",
    "    def forward(self, x_continuous, x_categorical):\n",
    "        \"\"\"\n",
    "        x_continuous shape: (batch_size, seq_length, num_continuous_features)\n",
    "        x_categorical shape: (batch_size, seq_length, num_categorical_features)\n",
    "        \"\"\"\n",
    "        # 1. Applica gli embedding\n",
    "        embedded_features = []\n",
    "        for i, emb_layer in enumerate(self.embedding_layers):\n",
    "            # Prendi la i-esima feature categorica per tutti i timestep\n",
    "            cat_feature = x_categorical[:, :, i]\n",
    "            embedded_features.append(emb_layer(cat_feature))\n",
    "\n",
    "        # 2. Concatena gli embedding\n",
    "        # embedded_features Ã¨ una lista di tensori (batch, seq, emb_dim)\n",
    "        # li concateniamo lungo l'ultima dimensione\n",
    "        x_embedded = torch.cat(embedded_features, dim=-1)\n",
    "\n",
    "        # 3. Concatena le feature continue con quelle embedded\n",
    "        x_combined = torch.cat([x_continuous, x_embedded], dim=-1)\n",
    "\n",
    "        # Convolutional layer\n",
    "        if self.use_conv:\n",
    "            # x_combined: (batch, seq, features) -> permute\n",
    "            x_conv = x_combined.permute(0, 2, 1)  # (batch, features, seq)\n",
    "            x_conv = self.conv_block(x_conv)  # (batch, conv_filters, seq')\n",
    "            # Riporta a (batch, seq', features_conv)\n",
    "            x_processed = x_conv.permute(0, 2, 1)\n",
    "            x_processed = self.pre_rnn_dropout(x_processed)\n",
    "        else:\n",
    "            x_processed = self.pre_rnn_dropout(x_combined)\n",
    "\n",
    "        # 4. Passa il tensore combinato alla RNN\n",
    "        # rnn_out contiene gli output per ogni timestep: (batch, seq_len, hidden_dim * num_directions)\n",
    "        rnn_out, hidden = self.rnn(x_processed)\n",
    "\n",
    "        # Estrai l'ultimo hidden state per il ramo senza attention\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            hidden = hidden[0]  # Per LSTM, hidden Ã¨ una tupla (h, c)\n",
    "\n",
    "        if self.bidirectional:\n",
    "            # Concatena forward e backward dell'ultimo layer\n",
    "            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n",
    "            hidden_to_classify = torch.cat([hidden[-1, 0, :, :], hidden[-1, 1, :, :]], dim=1)\n",
    "        else:\n",
    "            # Prendi l'ultimo layer\n",
    "            hidden_to_classify = hidden[-1]\n",
    "\n",
    "        # Due rami: con/senza attention\n",
    "        if self.use_attention:\n",
    "            # Ramo CON attention\n",
    "            # Applica attention sulla sequenza rnn_out: (batch, seq_len, rnn_output_dim)\n",
    "            x_att = self.attention(rnn_out)  # Output: (batch, seq_len, rnn_output_dim)\n",
    "            # Pooling temporale (mean pooling sui timestep)\n",
    "            x_pooled = x_att.mean(dim=1)  # Output: (batch, rnn_output_dim)\n",
    "            x_pooled = self.post_rnn_dropout(x_pooled)\n",
    "        else:\n",
    "            # Ramo SENZA attention (comportamento originale)\n",
    "            # Usa direttamente l'ultimo hidden state\n",
    "            x_pooled = self.post_rnn_dropout(hidden_to_classify)\n",
    "\n",
    "        # Classificatore finale (stesso per entrambi i rami)\n",
    "        logits = self.classifier(x_pooled)  # Output: (batch, num_classes)\n",
    "        return logits"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "42a2e099723b2e2e",
   "metadata": {
    "id": "42a2e099723b2e2e"
   },
   "source": [
    "## ðŸ§® **Network and Training Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "id": "6886410170bd226d",
   "metadata": {
    "id": "6886410170bd226d"
   },
   "source": [
    "# Cross-validation\n",
    "K = 5  # Number of splits (5 and 10 are considered good values)\n",
    "N_VAL_SAMPLE_INDEXES = int(VALIDATION_SET_PERCENTAGE * len(unique_samples))\n",
    "N_TEST_SAMPLE_INDEXES = int(TEST_SET_PERCENTAGE * len(unique_samples))\n",
    "\n",
    "# Training\n",
    "EPOCHS = 500  # Maximum epochs (increase to improve performance)\n",
    "PATIENCE = 50  # Early stopping patience (increase to improve performance)\n",
    "VERBOSE = 20  # Print frequency\n",
    "\n",
    "# Optimisation\n",
    "LEARNING_RATE = 7e-4  # Learning rate\n",
    "BATCH_SIZE = 512  # Batch size\n",
    "WINDOW_SIZE = 20  # Input window size\n",
    "STRIDE = 10  # Input stride\n",
    "\n",
    "# Architecture\n",
    "HIDDEN_LAYERS = 2  # Hidden layers\n",
    "HIDDEN_SIZE = 128  # Neurons per layer\n",
    "RNN_TYPE = 'LSTM'  # Type of RNN architecture\n",
    "BIDIRECTIONAL = True  # Bidirectional RNN\n",
    "\n",
    "# Regularisation\n",
    "DROPOUT_RATE = 0.5  # Dropout probability for external dropout (pre/post RNN)\n",
    "RNN_INSIDE_DROPOUT = 0.3  # Dropout probability used inside the RNN layers\n",
    "L1_LAMBDA = 1e-4\n",
    "L2_LAMBDA = 1e-2\n",
    "\n",
    "# Label smoothing\n",
    "LABEL_SMOOTHING = 0.02\n",
    "\n",
    "# Gradient Clipping\n",
    "MAX_GRADIENT_NORM = 0.5\n",
    "\n",
    "# Padding Strategy\n",
    "PADDING_STRATEGY = 'adaptive'  # Options: 'adaptive', 'repeat', 'zero'\n",
    "PADDING_LOOKBACK_STEPS = (STRIDE * 2) % WINDOW_SIZE  # Number of timesteps for adaptive padding statistics\n",
    "\n",
    "# Embedding dims for categorical dimensions\n",
    "MIN_N_EMBEDDING_DIMS = 20"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convolution 1d\n",
    "\n",
    "USE_CONV = False\n",
    "CONV_NUM_FILTERS = 64\n",
    "CONV_KERNEL_SIZE = 5\n",
    "CONV_NUM_LAYERS = 1\n",
    "CONV_STRIDE = 1\n",
    "CONV_POOL = None\n",
    "CONV_BATCH_NORM = True\n",
    "\n",
    "# Attention Layer\n",
    "USE_ATTENTION = True  # Enable/disable attention mechanism"
   ],
   "id": "f81c2c33ecab3a87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ðŸ“‰ **Learning Rate Scheduler Configuration**\n",
    "\n",
    "Il training ora supporta diversi tipi di learning rate schedulers:\n",
    "\n",
    "**Scheduler disponibili:**\n",
    "- `'reduce_on_plateau'`: Riduce LR quando il metric si stabilizza\n",
    "- `'cosine'`: Cosine Annealing - Riduzione smooth del LR\n",
    "- `'step'`: StepLR - Riduce LR ogni N epochs\n",
    "\n",
    "**Come usare:**\n",
    "1. Imposta `USE_SCHEDULER = True` nella sezione hyperparameters\n",
    "2. Scegli `SCHEDULER_TYPE` (default: 'reduce_on_plateau')\n",
    "3. Configura i parametri specifici dello scheduler se necessario\n",
    "\n",
    "Lo scheduler viene automaticamente integrato nel training loop e il learning rate viene tracciato in TensorBoard."
   ],
   "id": "a4ef0b8dbfa848ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Learning Rate Scheduler\n",
    "USE_SCHEDULER = False  # Enable/disable scheduler\n",
    "SCHEDULER_TYPE = 'cosine'  # Options: 'reduce_on_plateau', 'cosine', 'step'\n",
    "SCHEDULER_PATIENCE = 10  # For ReduceLROnPlateau\n",
    "SCHEDULER_FACTOR = 0.8  # For ReduceLROnPlateau and StepLR\n",
    "SCHEDULER_STEP_SIZE = 30  # For StepLR"
   ],
   "id": "ae7be6ddd7d2553c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fb5d375c8634b150",
   "metadata": {
    "id": "fb5d375c8634b150"
   },
   "source": [
    "# Definiamo le cardinalitÃ  (numero di valori unici) per ogni feature categorica.\n",
    "# La cardinalitÃ  deve essere il valore massimo della categoria.\n",
    "# Questo assicura che tutti gli indici siano validi per il layer di embedding.\n",
    "categorical_cardinalities = [\n",
    "    int(df_dataset_reduced['n_eyes'].max() + 1),\n",
    "    int(df_dataset_reduced['pain_survey_1'].max() + 1),\n",
    "    int(df_dataset_reduced['pain_survey_2'].max() + 1),\n",
    "    int(df_dataset_reduced['pain_survey_3'].max() + 1),\n",
    "    int(df_dataset_reduced['pain_survey_4'].max() + 1)\n",
    "]\n",
    "\n",
    "# Definiamo la dimensione dell'embedding per ogni feature.\n",
    "embedding_dims = [max(MIN_N_EMBEDDING_DIMS, (c + 1) // 2) for c in categorical_cardinalities]  #= [2,2,2,2,2,2,2]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Small test to check if model compiles and runs",
   "id": "759ecb3aeb38b1cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CELLA DI SANITY CHECK PER IL MODELLO -> se non da errore ignorala\n",
    "# Sanity check: forme con e senza attention\n",
    "\n",
    "batch_size = 4\n",
    "seq_len = WINDOW_SIZE\n",
    "\n",
    "n_cont = len(CONTINUOUS_COLS_REDUCED)\n",
    "n_cat = len(CATEGORICAL_COLS_REDUCED)\n",
    "\n",
    "# 1) Input continui: qualsiasi valore reale va bene\n",
    "x_cont = torch.randn(batch_size, seq_len, n_cont, device=device)\n",
    "\n",
    "# 2) Input categoriali: rispetta la cardinalitÃ  per ogni colonna\n",
    "x_cat = torch.zeros(batch_size, seq_len, n_cat, dtype=torch.long, device=device)\n",
    "\n",
    "for i, cardinality in enumerate(categorical_cardinalities):\n",
    "    # per la i-esima feature, gli indici validi sono [0, cardinality-1]\n",
    "    x_cat[:, :, i] = torch.randint(\n",
    "        low=0,\n",
    "        high=cardinality,\n",
    "        size=(batch_size, seq_len),\n",
    "        dtype=torch.long,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "# 3) Istanzia il modello di test\n",
    "model_test = RecurrentClassifier(\n",
    "    continuous_input_size=n_cont,\n",
    "    categorical_cardinalities=categorical_cardinalities,\n",
    "    embedding_dims=embedding_dims,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=HIDDEN_LAYERS,\n",
    "    num_classes=num_classes,\n",
    "    rnn_type=RNN_TYPE,\n",
    "    bidirectional=BIDIRECTIONAL,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    rnn_inside_dropout=RNN_INSIDE_DROPOUT,\n",
    "    use_conv=USE_CONV,\n",
    "    conv_num_filters=CONV_NUM_FILTERS,\n",
    "    conv_kernel_size=CONV_KERNEL_SIZE,\n",
    "    conv_num_layers=CONV_NUM_LAYERS,\n",
    "    conv_stride=CONV_STRIDE,\n",
    "    conv_pool=CONV_POOL,\n",
    "    conv_batch_norm=CONV_BATCH_NORM,\n",
    "    use_attention=USE_ATTENTION,  # prova con True/False\n",
    ").to(device)\n",
    "\n",
    "model_test.eval()\n",
    "with torch.no_grad():\n",
    "    y = model_test(x_cont, x_cat)\n",
    "\n",
    "print(\"logits shape:\", y.shape)\n",
    "print(\"expected:    \", (batch_size, num_classes))"
   ],
   "id": "1c42a67f8d4ac142",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Define Param Grid and Cross-Validation Settings**",
   "id": "b88b30e16ea2d59"
  },
  {
   "cell_type": "code",
   "id": "5fd6952bc77c898d",
   "metadata": {
    "id": "5fd6952bc77c898d"
   },
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "EXPERIMENT_NAME = \"lstm_colsRemoved\"  #spostato qui che mi ero rotto di scorrere #Legittimo bisogno\n",
    "\n",
    "# Set up TensorBoard logging and save model architecture\n",
    "writer = SummaryWriter(\"./\" + logs_dir + \"/\" + EXPERIMENT_NAME)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "15a61df8bb3c299b",
   "metadata": {
    "id": "15a61df8bb3c299b"
   },
   "source": [
    "# Define parameters to search\n",
    "param_grid = {\n",
    "\n",
    "}\n",
    "\n",
    "# Fixed hyperparameters (not being tuned)\n",
    "fixed_params = {\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'window_size': WINDOW_SIZE,\n",
    "    'stride': STRIDE,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'l1_lambda': L1_LAMBDA,\n",
    "    'l2_lambda': L2_LAMBDA,\n",
    "    'rnn_type': RNN_TYPE,\n",
    "    'bidirectional': BIDIRECTIONAL,\n",
    "    'embedding_dims': embedding_dims,\n",
    "    'label_smoothing': LABEL_SMOOTHING,\n",
    "    'continuous_cols': CONTINUOUS_COLS_REDUCED,\n",
    "    'categorical_cols': CATEGORICAL_COLS_REDUCED,\n",
    "    'labels_df': labels_df,\n",
    "    'hidden_layers': HIDDEN_LAYERS,\n",
    "    'hidden_size': HIDDEN_SIZE,\n",
    "    'dropout_rate': DROPOUT_RATE,\n",
    "    'rnn_inside_dropout': RNN_INSIDE_DROPOUT,\n",
    "    'padding_strategy': PADDING_STRATEGY,\n",
    "    'padding_lookback_steps': PADDING_LOOKBACK_STEPS,\n",
    "    'use_scheduler': USE_SCHEDULER,\n",
    "    'scheduler_type': SCHEDULER_TYPE,\n",
    "    'scheduler_patience': SCHEDULER_PATIENCE,\n",
    "    'scheduler_factor': SCHEDULER_FACTOR,\n",
    "    'scheduler_step_size': SCHEDULER_STEP_SIZE,\n",
    "\n",
    "    \"use_conv\": USE_CONV,\n",
    "    \"conv_num_filters\": CONV_NUM_FILTERS,\n",
    "    \"conv_kernel_size\": CONV_KERNEL_SIZE,\n",
    "    \"conv_num_layers\": CONV_NUM_LAYERS,\n",
    "    \"conv_pool\": CONV_POOL,\n",
    "    \"conv_stride\": CONV_STRIDE,\n",
    "    \"conv_batch_norm\": CONV_BATCH_NORM,\n",
    "\n",
    "    \"use_attention\": USE_ATTENTION,\n",
    "}\n",
    "\n",
    "# Cross-validation settings\n",
    "cv_params = {\n",
    "    'epochs': EPOCHS,\n",
    "    'device': device,\n",
    "    'k': K,\n",
    "    'n_val_sample_indexes': N_VAL_SAMPLE_INDEXES,\n",
    "    'n_test_sample_indexes': N_TEST_SAMPLE_INDEXES,\n",
    "    'patience': PATIENCE,\n",
    "    'verbose': VERBOSE,\n",
    "    'seed': SEED,\n",
    "    'evaluation_metric': \"val_f1\",\n",
    "    'mode': 'max',\n",
    "    'restore_best_weights': True,\n",
    "    'writer': writer,\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "587cbc3f9aa12b85",
   "metadata": {
    "id": "587cbc3f9aa12b85"
   },
   "source": [
    "## ðŸ§  **Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286446591f8f3aaa",
   "metadata": {
    "id": "286446591f8f3aaa"
   },
   "source": [
    "### **Utility Functions**"
   ]
  },
  {
   "cell_type": "code",
   "id": "d2ff757937e5c33f",
   "metadata": {
    "id": "d2ff757937e5c33f"
   },
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0):\n",
    "    \"\"\"\n",
    "    Perform one complete training epoch through the entire training dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to train\n",
    "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
    "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
    "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
    "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "        l1_lambda (float): Lambda for L1 regularization\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Iterate through training batches\n",
    "    for batch_idx, (inputs_cont, inputs_cat, targets) in enumerate(train_loader):\n",
    "        # Move data to device (GPU/CPU)\n",
    "        inputs_cont, inputs_cat, targets = inputs_cont.to(device), inputs_cat.to(device), targets.to(device)\n",
    "\n",
    "        # Clear gradients from previous step\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Forward pass with mixed precision (if CUDA available)\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=(\n",
    "                device.type == 'cuda')):  # consider to add dtype=torch.float16 to improve speed\n",
    "            logits = model(inputs_cont, inputs_cat)\n",
    "            loss = criterion(logits, targets)\n",
    "\n",
    "            # Add L1 and L2 regularization\n",
    "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "            loss = loss + l1_lambda * l1_norm\n",
    "\n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # --- Gradient Clipping ---\n",
    "        # Unscale gradients before clipping to avoid clipping scaled gradients\n",
    "        scaler.unscale_(optimizer)\n",
    "        # Clip the gradients to a maximum norm (e.g., 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=MAX_GRADIENT_NORM)\n",
    "        # --- End of Clipping ---\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        running_loss += loss.item() * inputs_cont.size(0)\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        all_predictions.append(predictions.cpu().numpy())\n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_f1 = f1_score(\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_predictions),\n",
    "        average='weighted'\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_f1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a34989395bcf9b2a",
   "metadata": {
    "id": "a34989395bcf9b2a"
   },
   "source": [
    "def validate_one_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Perform one complete validation epoch through the entire validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n",
    "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
    "        criterion (nn.Module): Loss function used to calculate validation loss\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy, all_predictions_np, all_targets_np) -\n",
    "               Validation loss, accuracy, and numpy arrays of predictions and true labels for this epoch\n",
    "\n",
    "    Note:\n",
    "        This function automatically sets the model to evaluation mode and disables\n",
    "        gradient computation for efficiency during validation.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Disable gradient computation for validation\n",
    "    with torch.no_grad():\n",
    "        for inputs_cont, inputs_cat, targets in val_loader:\n",
    "            # Sposta i dati sul dispositivo corretto\n",
    "            inputs_cont, inputs_cat, targets = inputs_cont.to(device), inputs_cat.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass with mixed precision (if CUDA available)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                logits = model(inputs_cont, inputs_cat)\n",
    "                loss = criterion(logits, targets)\n",
    "\n",
    "            # Accumulate metrics\n",
    "            running_loss += loss.item() * inputs_cont.size(0)\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "\n",
    "    all_predictions_np = np.concatenate(all_predictions)\n",
    "    all_targets_np = np.concatenate(all_targets)\n",
    "\n",
    "    epoch_accuracy = f1_score(\n",
    "        all_targets_np,\n",
    "        all_predictions_np,\n",
    "        average='weighted'\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_accuracy, all_predictions_np, all_targets_np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_scheduler(optimizer, scheduler_type, train_loader, epochs, **kwargs):\n",
    "    \"\"\"\n",
    "    Create learning rate scheduler based on configuration.\n",
    "\n",
    "    Args:\n",
    "        optimizer: PyTorch optimizer\n",
    "        scheduler_type: Type of scheduler ('reduce_on_plateau', 'cosine', 'step')\n",
    "        train_loader: DataLoader for calculating steps_per_epoch\n",
    "        epochs: Total number of epochs\n",
    "        **kwargs: Additional scheduler-specific parameters\n",
    "\n",
    "    Returns:\n",
    "        scheduler or None\n",
    "    \"\"\"\n",
    "    if scheduler_type == 'reduce_on_plateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='max',\n",
    "            factor=kwargs.get('scheduler_factor', 0.5),\n",
    "            patience=kwargs.get('scheduler_patience', 10),\n",
    "        )\n",
    "    elif scheduler_type == 'cosine':\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=epochs,\n",
    "            eta_min=kwargs.get('learning_rate', 1e-3) * 0.05\n",
    "        )\n",
    "    elif scheduler_type == 'step':\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size=kwargs.get('scheduler_step_size', 30),\n",
    "            gamma=kwargs.get('scheduler_factor', 0.5)\n",
    "        )\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    return scheduler"
   ],
   "id": "6a5b05d08e6d72b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def log_metrics_to_tensorboard(writer: SummaryWriter, epoch, train_loss, train_f1, val_loss, val_f1, model):\n",
    "    \"\"\"\n",
    "    Log training metrics and model parameters to TensorBoard for visualization.\n",
    "\n",
    "    Args:\n",
    "        writer (SummaryWriter): TensorBoard SummaryWriter object for logging\n",
    "        epoch (int): Current epoch number (used as x-axis in TensorBoard plots)\n",
    "        train_loss (float): Training loss for this epoch\n",
    "        train_f1 (float): Training f1 score for this epoch\n",
    "        val_loss (float): Validation loss for this epoch\n",
    "        val_f1 (float): Validation f1 score for this epoch\n",
    "        model (nn.Module): The neural network model (for logging weights/gradients)\n",
    "\n",
    "    Note:\n",
    "        This function logs scalar metrics (loss/f1 score) and histograms of model\n",
    "        parameters and gradients, which helps monitor training progress and detect\n",
    "        issues like vanishing/exploding gradients.\n",
    "    \"\"\"\n",
    "    # Log scalar metrics\n",
    "    writer.add_scalar('Loss/Training', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "    writer.add_scalar('F1/Training', train_f1, epoch)\n",
    "    writer.add_scalar('F1/Validation', val_f1, epoch)\n",
    "\n",
    "    # Log model parameters and gradients\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            # Check if the tensor is not empty before adding a histogram\n",
    "            if param.numel() > 0:\n",
    "                writer.add_histogram(f'{name}/weights', param.data, epoch)\n",
    "            if param.grad is not None:\n",
    "                # Check if the gradient tensor is not empty before adding a histogram\n",
    "                if param.grad.numel() > 0:\n",
    "                    if param.grad is not None and torch.isfinite(param.grad).all():\n",
    "                        writer.add_histogram(f'{name}/gradients', param.grad.data, epoch)"
   ],
   "id": "9e700ee2136d079f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "630fe43b1e6922dc",
   "metadata": {
    "id": "630fe43b1e6922dc"
   },
   "source": [
    "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n",
    "        scheduler=None, l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
    "        restore_best_weights=True, writer=None, verbose=10, experiment_name=\"\"):\n",
    "    \"\"\"\n",
    "    Train the neural network model on the training data and validate on the validation data.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to train\n",
    "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
    "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
    "        epochs (int): Number of training epochs\n",
    "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
    "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
    "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "        scheduler (optional): Learning rate scheduler (default: None)\n",
    "        l1_lambda (float): L1 regularization coefficient (default: 0)\n",
    "        l2_lambda (float): L2 regularization coefficient (default: 0)\n",
    "        patience (int): Number of epochs to wait for improvement before early stopping (default: 0)\n",
    "        evaluation_metric (str): Metric to monitor for early stopping (default: \"val_f1\")\n",
    "        mode (str): 'max' for maximizing the metric, 'min' for minimizing (default: 'max')\n",
    "        restore_best_weights (bool): Whether to restore model weights from best epoch (default: True)\n",
    "        writer (SummaryWriter, optional): TensorBoard SummaryWriter object for logging (default: None)\n",
    "        verbose (int, optional): Frequency of printing training progress (default: 10)\n",
    "        experiment_name (str, optional): Experiment name for saving models (default: \"\")\n",
    "\n",
    "    Returns:\n",
    "        tuple: (model, training_history, best_val_preds_np, best_val_targets_np) -\n",
    "               Trained model, metrics history, best validation predictions, and best validation true labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize metrics tracking\n",
    "    training_history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_f1': [], 'val_f1': [], 'learning_rate': []\n",
    "    }\n",
    "\n",
    "    best_val_preds_np = np.array([])\n",
    "    best_val_targets_np = np.array([])\n",
    "\n",
    "    # Configure early stopping if patience is set\n",
    "    if patience > 0:\n",
    "        patience_counter = 0\n",
    "        best_metric = float('-inf') if mode == 'max' else float('inf')\n",
    "        best_epoch = 0\n",
    "\n",
    "    print(f\"Training {epochs} epochs...\")\n",
    "\n",
    "    # Main training loop: iterate through epochs\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        # Forward pass through training data, compute gradients, update weights\n",
    "        train_loss, train_f1 = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, scaler, device, l1_lambda\n",
    "        )\n",
    "\n",
    "        # Evaluate model on validation data without updating weights\n",
    "        val_loss, val_f1, current_val_preds, current_val_targets = validate_one_epoch(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        # Store metrics for plotting and analysis\n",
    "        training_history['train_loss'].append(train_loss)\n",
    "        training_history['val_loss'].append(val_loss)\n",
    "        training_history['train_f1'].append(train_f1)\n",
    "        training_history['val_f1'].append(val_f1)\n",
    "\n",
    "        # Track current learning rate\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        training_history['learning_rate'].append(current_lr)\n",
    "\n",
    "        # Write metrics to TensorBoard for visualization\n",
    "        if writer is not None:\n",
    "            log_metrics_to_tensorboard(\n",
    "                writer, epoch, train_loss, train_f1, val_loss, val_f1, model\n",
    "            )\n",
    "            writer.add_scalar('Learning_Rate', current_lr, epoch)\n",
    "\n",
    "        # Print progress every N epochs or on first epoch\n",
    "        if verbose > 0:\n",
    "            if epoch % verbose == 0 or epoch == 1:\n",
    "                print(f\"Epoch {epoch:3d}/{epochs} | \"\n",
    "                      f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f} | \"\n",
    "                      f\"Val: Loss={val_loss:.4f}, F1 Score={val_f1:.4f} | \"\n",
    "                      f\"LR={current_lr:.2e}\")\n",
    "\n",
    "        # Step the learning rate scheduler\n",
    "        if scheduler is not None:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                # ReduceLROnPlateau needs the metric\n",
    "                scheduler.step(val_f1 if mode == 'max' else val_loss)\n",
    "            else:\n",
    "                # Other schedulers just need epoch\n",
    "                scheduler.step()\n",
    "\n",
    "        # Early stopping logic: monitor metric and save best model\n",
    "        if patience > 0:\n",
    "            current_metric = training_history[evaluation_metric][-1]\n",
    "            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n",
    "\n",
    "            if is_improvement:\n",
    "                best_metric = current_metric\n",
    "                best_epoch = epoch\n",
    "                torch.save(model.state_dict(), \"models/\" + experiment_name + '_model.pt')\n",
    "                best_val_preds_np = current_val_preds\n",
    "                best_val_targets_np = current_val_targets\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping triggered after {epoch} epochs.\")\n",
    "                    break\n",
    "\n",
    "    # Restore best model weights if early stopping was used\n",
    "    if restore_best_weights and patience > 0:\n",
    "        model.load_state_dict(torch.load(\"models/\" + experiment_name + '_model.pt'))\n",
    "        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n",
    "\n",
    "    # Save final model if no early stopping\n",
    "    if patience == 0:\n",
    "        torch.save(model.state_dict(), \"models/\" + experiment_name + '_model.pt')\n",
    "\n",
    "    # Close TensorBoard writer\n",
    "    if writer is not None:\n",
    "        writer.close()\n",
    "\n",
    "    return model, training_history, best_val_preds_np, best_val_targets_np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "814f404d42804aef"
   },
   "cell_type": "code",
   "source": [
    "def get_max_score(scores):\n",
    "    \"\"\"\n",
    "    Extract the maximum score from a dictionary of scores.\n",
    "\n",
    "    Args:\n",
    "        scores: Dict with keys like 'split_0', 'split_1', ..., 'mean', 'std'\n",
    "\n",
    "    Returns:\n",
    "        max_score: Maximum score across splits\n",
    "    \"\"\"\n",
    "    split_scores = [v for k, v in scores.items() if k.startswith('split_')]\n",
    "    return max(split_scores) if split_scores else None"
   ],
   "id": "814f404d42804aef",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2c563e24c8fd3f8a",
   "metadata": {
    "id": "2c563e24c8fd3f8a"
   },
   "source": [
    "### **Cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "id": "5764e050e790fa5b",
   "metadata": {
    "id": "5764e050e790fa5b"
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def k_shuffle_split_cross_validation_round_rnn(\n",
    "        df,\n",
    "        labels_df,\n",
    "        continuous_cols,\n",
    "        categorical_cols,\n",
    "        device,\n",
    "        n_val_sample_indexes,\n",
    "        n_test_sample_indexes,\n",
    "        hidden_layers,\n",
    "        hidden_size,\n",
    "        cols_to_exclude_from_normalization=None,\n",
    "        epochs=500,\n",
    "        k=5,\n",
    "        batch_size=512,\n",
    "        learning_rate=1e-3,\n",
    "        dropout_rate=0.2,\n",
    "        rnn_inside_dropout=0.2,\n",
    "        window_size=200,\n",
    "        stride=50,\n",
    "        rnn_type='GRU',\n",
    "        bidirectional=False,\n",
    "        embedding_dims=embedding_dims,\n",
    "        l1_lambda=0,\n",
    "        l2_lambda=0,\n",
    "        patience=50,\n",
    "        evaluation_metric=\"val_f1\",\n",
    "        mode='max',\n",
    "        restore_best_weights=True,\n",
    "        writer=None,\n",
    "        verbose=10,\n",
    "        seed=42,\n",
    "        experiment_name=\"rnn_k_shuffle_split\",\n",
    "        label_smoothing=0.1,\n",
    "        plot_confusion_matrix=False,\n",
    "        padding_strategy='adaptive',\n",
    "        padding_lookback_steps=10,\n",
    "        use_scheduler=True,\n",
    "        scheduler_type='onecycle',\n",
    "        scheduler_patience=10,\n",
    "        scheduler_factor=0.5,\n",
    "        scheduler_step_size=30,\n",
    "        use_conv: bool = False,\n",
    "        conv_num_filters: int = 64,\n",
    "        conv_kernel_size: int = 5,\n",
    "        conv_num_layers: int = 1,\n",
    "        conv_stride: int = 1,\n",
    "        conv_pool: Optional[int] = None,\n",
    "        conv_batch_norm: bool = True,\n",
    "        use_attention=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    K-shuffle-split cross validation per il dataset Pirate Pain.\n",
    "    Split basato su sample_index (nessuna leakage tra split).\n",
    "    Costruisce sequenze separate in feature continue e categoriche giÃ  previste dal modello.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame con le feature (incluso sample_index)\n",
    "        labels_df: DataFrame con colonne ['sample_index','label']\n",
    "        continuous_cols: lista colonne continue\n",
    "        categorical_cols: lista colonne categoriche (giÃ  integer-encoded, valori negativi verranno rimappati a 0)\n",
    "        epochs, device, k, ... : come da pipeline esistente\n",
    "        embedding_dims: lista dimensioni embedding (se None calcolate automaticamente)\n",
    "    Returns:\n",
    "        fold_losses: dict split_i -> lista val_loss per epoca\n",
    "        fold_metrics: dict split_i -> lista val_f1 per epoca\n",
    "        best_scores: dict con best f1 per split + mean/std\n",
    "    \"\"\"\n",
    "\n",
    "    # Sanity\n",
    "    if cols_to_exclude_from_normalization is None:\n",
    "        cols_to_exclude_from_normalization = []\n",
    "    assert all(c in df.columns for c in continuous_cols), \"Colonne continue mancanti\"\n",
    "    assert all(c in df.columns for c in categorical_cols), \"Colonne categoriche mancanti\"\n",
    "    assert 'sample_index' in df.columns, \"Manca sample_index\"\n",
    "\n",
    "    # Initialise containers for results across all splits\n",
    "    fold_losses = {}\n",
    "    fold_metrics = {}\n",
    "    best_scores = {}\n",
    "\n",
    "    # Inizializza modello\n",
    "    model = RecurrentClassifier(\n",
    "        continuous_input_size=len(continuous_cols),\n",
    "        categorical_cardinalities=categorical_cardinalities,\n",
    "        embedding_dims=embedding_dims,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=hidden_layers,\n",
    "        num_classes=num_classes,\n",
    "        rnn_type=rnn_type,\n",
    "        bidirectional=bidirectional,\n",
    "        dropout_rate=dropout_rate,\n",
    "        rnn_inside_dropout=rnn_inside_dropout,\n",
    "        use_conv=use_conv,\n",
    "        conv_num_filters=conv_num_filters,\n",
    "        conv_kernel_size=conv_kernel_size,\n",
    "        conv_num_layers=conv_num_layers,\n",
    "        conv_stride=conv_stride,\n",
    "        conv_pool=conv_pool,\n",
    "        conv_batch_norm=conv_batch_norm,\n",
    "        use_attention=use_attention,\n",
    "    ).to(device)\n",
    "\n",
    "    # Store initial weights to reset model for each split\n",
    "    initial_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # Create directory for model checkpoints\n",
    "    os.makedirs(f\"models/{experiment_name}\", exist_ok=True)\n",
    "\n",
    "    for split_idx in range(k):\n",
    "        if verbose > 0:\n",
    "            print(f\"Split {split_idx + 1}/{k}\")\n",
    "\n",
    "        # Reset model to initial weights for fair comparison across splits\n",
    "        model.load_state_dict(initial_state)\n",
    "\n",
    "        # Stratified split su sample_index per mantenere la distribuzione delle label\n",
    "        labels_map = labels_df.set_index('sample_index')['label']\n",
    "        y_all = np.array([labels_map[sid] for sid in unique_samples], dtype=np.int64)\n",
    "\n",
    "        # Primo split: train vs (val+test)\n",
    "        train_ids, temp_ids, y_train, y_temp = train_test_split(\n",
    "            unique_samples,\n",
    "            y_all,\n",
    "            test_size=n_val_sample_indexes + n_test_sample_indexes,\n",
    "            stratify=y_all,\n",
    "            random_state=seed + split_idx,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        # Secondo split: val vs test\n",
    "        val_ids, test_ids, y_val, y_test = train_test_split(\n",
    "            temp_ids,\n",
    "            y_temp,\n",
    "            test_size=n_test_sample_indexes,\n",
    "            stratify=y_temp,\n",
    "            random_state=seed + split_idx,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        n_train_samples = len(train_ids)\n",
    "        assert n_train_samples > 0, \"Train set vuoto, riduci val/test\"\n",
    "\n",
    "        df_train = df[df['sample_index'].isin(train_ids)].copy()\n",
    "        df_val = df[df['sample_index'].isin(val_ids)].copy()\n",
    "\n",
    "        # Crea il dataset di training, che calcolerÃ  e salverÃ  il suo scaler\n",
    "        scaler = StandardScaler()  #MinMaxScaler()  Normalizzo i dati usando media e varianza per vedere se cambia qualcosa\n",
    "        features_to_normalize = list(set(continuous_cols) - set(cols_to_exclude_from_normalization))\n",
    "        df_train[features_to_normalize] = scaler.fit_transform(df_train[features_to_normalize])\n",
    "        df_val[features_to_normalize] = scaler.transform(df_val[features_to_normalize])\n",
    "\n",
    "        # Salva lo scaler per l'inferenza futura\n",
    "        scaler_path = f\"models/{experiment_name}/split_{split_idx}_scaler.pkl\"\n",
    "        joblib.dump(scaler, scaler_path)\n",
    "\n",
    "        # Creazione delle sequenze con build_sequences\n",
    "        X_train_cont, X_train_cat, y_train = build_sequences(\n",
    "            df_train, labels_df, continuous_cols, categorical_cols,\n",
    "            window_size, stride, padding_strategy, padding_lookback_steps\n",
    "        )\n",
    "\n",
    "        X_val_cont, X_val_cat, y_val = build_sequences(\n",
    "            df_val, labels_df, continuous_cols, categorical_cols,\n",
    "            window_size, stride, padding_strategy, padding_lookback_steps\n",
    "        )\n",
    "\n",
    "        # Creazione di TensorDataset e DataLoader\n",
    "        train_ds = TensorDataset(torch.from_numpy(X_train_cont).float(), torch.from_numpy(X_train_cat).long(),\n",
    "                                 torch.from_numpy(y_train).long())\n",
    "        val_ds = TensorDataset(torch.from_numpy(X_val_cont).float(), torch.from_numpy(X_val_cat).long(),\n",
    "                               torch.from_numpy(y_val).long())\n",
    "\n",
    "        if verbose > 0:\n",
    "            print(f\"  Train sequences: {len(train_ds)} | Val sequences: {len(val_ds)}\")\n",
    "\n",
    "        # Create data loaders\n",
    "        train_loader = make_loader(train_ds, batch_size=batch_size, shuffle=False,\n",
    "                                   drop_last=False)  # drop_last=True puÃ² aiutare\n",
    "        val_loader = make_loader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "        # Calculate class weights for imbalanced dataset\n",
    "        # Calcolo pesi per class imbalance\n",
    "        class_counts = np.bincount(y_train)\n",
    "        total_samples = len(y_train)\n",
    "        class_weights = total_samples / (len(np.unique(y_train)) * class_counts)\n",
    "        class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=label_smoothing)\n",
    "\n",
    "        # Define optimizer with L2 regularization\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=l2_lambda)\n",
    "\n",
    "        # Create learning rate scheduler if enabled\n",
    "        scheduler = None\n",
    "        if use_scheduler:\n",
    "            scheduler = create_scheduler(\n",
    "                optimizer,\n",
    "                scheduler_type,\n",
    "                train_loader,\n",
    "                epochs,\n",
    "                learning_rate=learning_rate,\n",
    "                scheduler_patience=scheduler_patience,\n",
    "                scheduler_factor=scheduler_factor,\n",
    "                scheduler_step_size=scheduler_step_size\n",
    "            )\n",
    "            if verbose > 0:\n",
    "                print(f\"  Using {scheduler_type} scheduler\")\n",
    "\n",
    "        # Enable mixed precision training for GPU acceleration\n",
    "        split_scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "\n",
    "        _, training_history, best_val_preds_split, best_val_targets_split = fit(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            epochs=epochs,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            scaler=split_scaler,\n",
    "            device=device,\n",
    "            writer=writer,\n",
    "            patience=patience,\n",
    "            verbose=verbose,\n",
    "            l1_lambda=l1_lambda,\n",
    "            l2_lambda=l2_lambda,\n",
    "            evaluation_metric=evaluation_metric,\n",
    "            mode=mode,\n",
    "            restore_best_weights=restore_best_weights,\n",
    "            experiment_name=f\"{experiment_name}/split_{split_idx}\"\n",
    "        )\n",
    "\n",
    "        fold_losses[f\"split_{split_idx}\"] = training_history['val_loss']\n",
    "        fold_metrics[f\"split_{split_idx}\"] = training_history[evaluation_metric]\n",
    "        best_scores[f\"split_{split_idx}\"] = max(training_history[evaluation_metric])\n",
    "\n",
    "        # Plot confusion matrix for this split's best validation performance\n",
    "        if plot_confusion_matrix and len(best_val_preds_split) > 0:\n",
    "            from sklearn.metrics import confusion_matrix\n",
    "            cm_val = confusion_matrix(best_val_targets_split, best_val_preds_split)\n",
    "            labels_val = np.array([f\"{num}\" for num in cm_val.flatten()]).reshape(cm_val.shape)\n",
    "\n",
    "            plt.figure(figsize=(8, 7))\n",
    "            sns.heatmap(cm_val, annot=labels_val, fmt='', cmap='Blues')\n",
    "            plt.xlabel('Predicted labels')\n",
    "            plt.ylabel('True labels')\n",
    "            plt.title(f'Confusion Matrix - Validation Set (Split {split_idx + 1})')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    best_scores[\"mean\"] = float(np.mean(list(best_scores.values())))\n",
    "    best_scores[\"std\"] = float(np.std(list(best_scores.values())))\n",
    "\n",
    "    if verbose > 0:\n",
    "        print(\"\\n--- K-fold Validation Results ---\")\n",
    "        print(\n",
    "            f\"Best val_F1 score : {get_max_score(best_scores):.4f}, mean: {best_scores['mean']:.4f} \\u00b1 {best_scores['std']:.4f}\")\n",
    "\n",
    "    return fold_losses, fold_metrics, best_scores"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c8fe35b66342753",
   "metadata": {
    "id": "c8fe35b66342753"
   },
   "source": [
    "from itertools import product\n",
    "\n",
    "\n",
    "def grid_search_cv_rnn(df, param_grid, fixed_params, cv_params, verbose=True, plot_confusion_matrix=False):\n",
    "    \"\"\"\n",
    "    Execute grid search with K-shuffle-split cross-validation for RNN models on time series data.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with columns ['user_id', 'activity', 'x_axis', 'y_axis', 'z_axis', 'id']\n",
    "        param_grid: Dict of parameters to test, e.g. {'batch_size': [16, 32], 'rnn_type': ['LSTM', 'GRU']}\n",
    "        fixed_params: Dict of fixed hyperparameters (hidden_size, learning_rate, window_size, stride, etc.)\n",
    "        cv_params: Dict of CV settings (epochs, k, patience, criterion, scaler, device, etc.)\n",
    "        verbose: Print progress for each configuration\n",
    "\n",
    "    Returns:\n",
    "        results: Dict with scores for each configuration\n",
    "        best_config: Dict with best hyperparameter combination\n",
    "        best_score: Best mean F1 score achieved\n",
    "    \"\"\"\n",
    "    # Generate all parameter combinations\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_values = list(param_grid.values())\n",
    "    combinations = list(product(*param_values))\n",
    "\n",
    "    results = {}\n",
    "    best_score = -np.inf\n",
    "    best_config = None\n",
    "\n",
    "    total = len(combinations)\n",
    "\n",
    "    for idx, combo in enumerate(combinations, 1):\n",
    "        # Create current configuration dict\n",
    "        current_config = dict(zip(param_names, combo))\n",
    "        config_str = EXPERIMENT_NAME + \"_\".join([f\"{k}_{v}\" for k, v in current_config.items()]).replace('.', 'p')\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\nConfiguration {idx}/{total}:\")\n",
    "            for param, value in current_config.items():\n",
    "                print(f\"  {param}: {value}\")\n",
    "\n",
    "        # Merge current config with fixed parameters\n",
    "        run_params = {**fixed_params, **current_config}\n",
    "\n",
    "        # Execute cross-validation\n",
    "        _, _, fold_scores = k_shuffle_split_cross_validation_round_rnn(\n",
    "            df=df,\n",
    "            experiment_name=config_str,\n",
    "            plot_confusion_matrix=plot_confusion_matrix,\n",
    "            cols_to_exclude_from_normalization=COLS_TO_EXCLUDE_FROM_NORMALIZATION,\n",
    "            **run_params,\n",
    "            **cv_params\n",
    "        )\n",
    "\n",
    "        # Store results\n",
    "        results[config_str] = {**fold_scores}\n",
    "\n",
    "        # Track best configuration\n",
    "        current_max_score = get_max_score(fold_scores)\n",
    "        if current_max_score > best_score:\n",
    "            best_score = current_max_score\n",
    "            best_config = current_config.copy()\n",
    "            if verbose:\n",
    "                print(\" ---NEW BEST SCORE!---\\n\")\n",
    "\n",
    "    return results, best_config, best_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "479512efe289b8b0"
   },
   "cell_type": "code",
   "source": [
    "def plot_top_configurations_rnn(results, k_splits, top_n=5, figsize=(14, 7)):\n",
    "    \"\"\"\n",
    "    Visualise top N RNN configurations with boxplots of F1 scores across CV splits.\n",
    "\n",
    "    Args:\n",
    "        results: Dict of results from grid_search_cv_rnn\n",
    "        k_splits: Number of CV splits used\n",
    "        top_n: Number of top configurations to display\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    # Sort by max score across splits\n",
    "    config_scores = {\n",
    "        name: max(v for k, v in data.items() if k.startswith('split_'))\n",
    "        for name, data in results.items()\n",
    "    }\n",
    "    sorted_configs = sorted(config_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Select top N\n",
    "    top_configs = sorted_configs[:min(top_n, len(sorted_configs))]\n",
    "\n",
    "    # Prepare boxplot data\n",
    "    boxplot_data = []\n",
    "    labels = []\n",
    "\n",
    "    # Define a dictionary for replacements, ordered to handle prefixes correctly\n",
    "    replacements = {\n",
    "        'batch_size_': 'BS=',\n",
    "        'learning_rate_': '\\nLR=',\n",
    "        'hidden_layers_': '\\nHL=',\n",
    "        'hidden_size_': '\\nHS=',\n",
    "        'dropout_rate_': '\\nDR=',\n",
    "        'window_size_': '\\nWS=',\n",
    "        'stride_': '\\nSTR=',\n",
    "        'rnn_type_': '\\nRNN=',\n",
    "        'bidirectional_': '\\nBIDIR=',\n",
    "        'l1_lambda_': '\\nL1=',\n",
    "        'l2_lambda_': '\\nL2='\n",
    "    }\n",
    "\n",
    "    # Replacements for separators\n",
    "    separator_replacements = {\n",
    "        '_learning_rate_': '\\nLR=',\n",
    "        '_hidden_layers_': '\\nHL=',\n",
    "        '_hidden_size_': '\\nHS=',\n",
    "        '_dropout_rate_': '\\nDR=',\n",
    "        '_window_size_': '\\nWS=',\n",
    "        '_stride_': '\\nSTR=',\n",
    "        '_rnn_type_': '\\nRNN=',\n",
    "        '_bidirectional_': '\\nBIDIR=',\n",
    "        '_l1_lambda_': '\\nL1=',\n",
    "        '_l2_lambda_': '\\nL2=',\n",
    "        '_': ''\n",
    "    }\n",
    "\n",
    "    for config_name, best_score in top_configs:\n",
    "        # Extract best score from each split (auto-detect number of splits)\n",
    "        split_scores = []\n",
    "        for i in range(k_splits):\n",
    "            if f'split_{i}' in results[config_name]:\n",
    "                split_scores.append(results[config_name][f'split_{i}'])\n",
    "        boxplot_data.append(split_scores)\n",
    "\n",
    "        # Verify we have the expected number of splits\n",
    "        if len(split_scores) != k_splits:\n",
    "            print(f\"Warning: Config {config_name} has {len(split_scores)} splits, expected {k_splits}\")\n",
    "\n",
    "        # Create readable label using the replacements dictionary\n",
    "        readable_label = config_name\n",
    "        for old, new in replacements.items():\n",
    "            readable_label = readable_label.replace(old, new)\n",
    "\n",
    "        # Apply separator replacements\n",
    "        for old, new in separator_replacements.items():\n",
    "            readable_label = readable_label.replace(old, new)\n",
    "\n",
    "        labels.append(f\"{readable_label}\\n(max={best_score:.3f})\")\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    bp = ax.boxplot(boxplot_data, labels=labels, patch_artist=True,\n",
    "                    showmeans=True, meanline=True)\n",
    "\n",
    "    # Styling\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set_facecolor('lightblue')\n",
    "        patch.set_alpha(0.7)\n",
    "\n",
    "    # Highlight best configuration\n",
    "    ax.get_xticklabels()[0].set_fontweight('bold')\n",
    "\n",
    "    ax.set_ylabel('F1 Score')\n",
    "    ax.set_xlabel('Configuration')\n",
    "    ax.set_title(f'Top {len(top_configs)} RNN Configurations - F1 Score Distribution Across {k_splits} Splits')\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "    plt.xticks(rotation=0, ha='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "479512efe289b8b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "97802264915f35ad"
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# Function to save and print results in a readable format\n",
    "def save_grid_search_results(results, best_config, best_score, experiment_name=EXPERIMENT_NAME):\n",
    "    payload = {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"best_score\": float(best_score),\n",
    "        \"best_config\": best_config,\n",
    "        \"results\": results\n",
    "    }\n",
    "    json_path = f\"{experiment_name}.json\"\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"JSON file saved: {json_path}\")\n",
    "    print(\"\\n--- Grid Search Summary ---\")\n",
    "    print(f\"Best F1 (max split): {best_score:.4f}\")\n",
    "    print(\"Best configuration:\")\n",
    "    for k, v in best_config.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    # Individua e stampa lo split migliore in base a val_f1\n",
    "    best_cfg_name = None\n",
    "    best_split_name = None\n",
    "    best_split_value = None\n",
    "    for cfg_name, data in results.items():\n",
    "        split_items = {k: v for k, v in data.items() if k.startswith('split_')}\n",
    "        if not split_items:\n",
    "            continue\n",
    "        top_split_name = max(split_items, key=split_items.get)\n",
    "        top_split_value = split_items[top_split_name]\n",
    "        if top_split_value == best_score:\n",
    "            best_cfg_name = cfg_name\n",
    "            best_split_name = top_split_name\n",
    "            best_split_value = top_split_value\n",
    "            break\n",
    "    if best_cfg_name and best_split_name is not None:\n",
    "        print(f\"Best split: {best_cfg_name} -> {best_split_name} (val_f1={best_split_value:.4f})\")\n",
    "\n",
    "    print(\"\\nAll configurations (mean Â± std):\")\n",
    "    for cfg_name, data in results.items():\n",
    "        mean_score = data.get(\"mean\")\n",
    "        std_score = data.get(\"std\")\n",
    "        if mean_score is not None and std_score is not None:\n",
    "            print(f\"  {cfg_name}: {mean_score:.4f} Â± {std_score:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {cfg_name}: values not available\")"
   ],
   "id": "97802264915f35ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "id": "f7372398f2c512f9"
   },
   "cell_type": "markdown",
   "source": [
    "## **Grid Search**"
   ],
   "id": "f7372398f2c512f9"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1ea449378b6ddecb",
    "outputId": "b0c71a18-3591-4b48-c2a2-8b9ef981e20d"
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "# Execute search\n",
    "results, best_config, best_score = grid_search_cv_rnn(\n",
    "    df=df_dataset_reduced,\n",
    "    param_grid=param_grid,\n",
    "    fixed_params=fixed_params,\n",
    "    cv_params=cv_params,\n",
    "    plot_confusion_matrix=True  #Cambia qui se vuoi vedere le confusion matrix durante la grid search\n",
    ")"
   ],
   "id": "1ea449378b6ddecb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d79142114199aff8",
    "outputId": "69e3ee75-7edc-4e2e-d54f-111bdd54ec7c"
   },
   "cell_type": "code",
   "source": [
    "# Save and print\n",
    "save_grid_search_results(results, best_config, best_score)"
   ],
   "id": "d79142114199aff8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "14959bf9db418bee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "id": "14959bf9db418bee",
    "outputId": "c1e8dd1c-8cd8-4e8c-da4d-949db4396d68"
   },
   "source": [
    "# Visualise results\n",
    "plot_top_configurations_rnn(results, k_splits=K, top_n=5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "e9e2d20f6aea468d"
   },
   "cell_type": "code",
   "source": [
    "# --- 1. Combine fixed and best hyperparameters ---\n",
    "# 'fixed_params' and 'best_config' are loaded from the grid search cell\n",
    "final_best_params = {**fixed_params, **best_config}\n",
    "\n",
    "# Generate config string (from grid params only) to find saved model files\n",
    "# If best_config is empty (no params tuned), use EXPERIMENT_NAME directly as the key\n",
    "if not best_config:\n",
    "    best_config_str = EXPERIMENT_NAME\n",
    "else:\n",
    "    best_config_str = EXPERIMENT_NAME + \"_\".join([f\"{k}_{v}\" for k, v in best_config.items()]).replace('.', 'p')"
   ],
   "id": "e9e2d20f6aea468d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "839e2d5dc96e5b26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 973
    },
    "id": "839e2d5dc96e5b26",
    "outputId": "cf992972-0fd1-4b23-80c0-022679f7c40f"
   },
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "features_to_normalize = list(set(CONTINUOUS_COLS_REDUCED) - set(COLS_TO_EXCLUDE_FROM_NORMALIZATION))\n",
    "\n",
    "# Initialise lists for metrics\n",
    "test_accuracies = []\n",
    "test_precisions = []\n",
    "test_recall_scores = []\n",
    "test_f1_scores = []\n",
    "all_test_targets = []  # For aggregated confusion matrix\n",
    "all_test_preds = []  # For aggregated confusion matrix\n",
    "\n",
    "# --- 2. Begin evaluation loop across the K splits ---\n",
    "for split in range(K):\n",
    "    print(f\"Evaluating Split {split + 1}/{K} using best config: {best_config_str}\")\n",
    "\n",
    "    unique_samples = df_dataset_reduced['sample_index'].unique()\n",
    "\n",
    "    # --- 3. Regenera la esatta suddivisione dei dati per questo fold ---\n",
    "    # Questa logica deve essere identica a k_shuffle_split_cross_validation_round_rnn\n",
    "    # Stratified split su sample_index per mantenere la distribuzione delle label\n",
    "    labels_map = labels_df.set_index('sample_index')['label']\n",
    "    y_all = np.array([labels_map[sid] for sid in unique_samples], dtype=np.int64)\n",
    "\n",
    "    # Primo split: train vs (val+test)\n",
    "    train_ids, temp_ids, y_train, y_temp = train_test_split(\n",
    "        unique_samples,\n",
    "        y_all,\n",
    "        test_size=N_VAL_SAMPLE_INDEXES + N_TEST_SAMPLE_INDEXES,\n",
    "        stratify=y_all,\n",
    "        random_state=SEED + split,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Secondo split: val vs test\n",
    "    val_ids, test_ids, y_val, y_test = train_test_split(\n",
    "        temp_ids,\n",
    "        y_temp,\n",
    "        test_size=N_TEST_SAMPLE_INDEXES,\n",
    "        stratify=y_temp,\n",
    "        random_state=SEED + split,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    df_train = df_dataset_reduced[df_dataset_reduced['sample_index'].isin(train_ids)].copy()\n",
    "    df_test = df_dataset_reduced[df_dataset_reduced['sample_index'].isin(test_ids)].copy()\n",
    "\n",
    "    # Normalise features (fit on THIS split's training data)\n",
    "    mm_scaler = StandardScaler()  #MinMaxScaler()\n",
    "    df_train[features_to_normalize] = mm_scaler.fit_transform(df_train[features_to_normalize])\n",
    "    df_test[features_to_normalize] = mm_scaler.transform(df_test[features_to_normalize])\n",
    "\n",
    "    labels_df_split = labels_df[labels_df['sample_index'].isin(test_ids)].copy()\n",
    "\n",
    "    # --- 5. Build test sequences ---\n",
    "    # Use the best window/stride from final_best_params\n",
    "    X_test_cont, X_test_cat, y_test = build_sequences(\n",
    "        df_test,\n",
    "        labels_df_split,\n",
    "        continuous_cols=CONTINUOUS_COLS_REDUCED,\n",
    "        categorical_cols=CATEGORICAL_COLS_REDUCED,\n",
    "        window=final_best_params['window_size'],\n",
    "        stride=final_best_params['stride'],\n",
    "        padding_strategy=final_best_params.get('padding_strategy', 'adaptive'),\n",
    "        lookback_steps=final_best_params.get('padding_lookback_steps', 10)\n",
    "    )\n",
    "\n",
    "    # --- 6. Create the Test DataLoader ---\n",
    "    test_ds = TensorDataset(torch.from_numpy(X_test_cont).float(), torch.from_numpy(X_test_cat).long(),\n",
    "                            torch.from_numpy(y_test).long())\n",
    "    test_loader = make_loader(\n",
    "        test_ds,\n",
    "        batch_size=final_best_params['batch_size'],\n",
    "        shuffle=False,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    # Handle empty test sets from user splits\n",
    "    if len(test_ds) == 0:\n",
    "        print(f\"  WARNING: Test set for split {split + 1} is empty. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # --- 7. Initialise the Model ---\n",
    "    # Use the best architecture parameters from the grid search\n",
    "    model = RecurrentClassifier(\n",
    "        continuous_input_size=len(CONTINUOUS_COLS_REDUCED),\n",
    "        categorical_cardinalities=categorical_cardinalities,\n",
    "        embedding_dims=embedding_dims,\n",
    "        hidden_size=final_best_params['hidden_size'],\n",
    "        num_layers=final_best_params['hidden_layers'],\n",
    "        num_classes=num_classes,\n",
    "        dropout_rate=final_best_params['dropout_rate'],\n",
    "        rnn_inside_dropout=final_best_params.get('rnn_inside_dropout', 0.0),\n",
    "        bidirectional=final_best_params['bidirectional'],\n",
    "        rnn_type=final_best_params['rnn_type'],\n",
    "        use_conv=final_best_params.get('use_conv', False),\n",
    "        conv_num_filters=final_best_params.get('conv_num_filters', 64),\n",
    "        conv_kernel_size=final_best_params.get('conv_kernel_size', 5),\n",
    "        conv_num_layers=final_best_params.get('conv_num_layers', 1),\n",
    "        conv_stride=final_best_params.get('conv_stride', 1),\n",
    "        conv_pool=final_best_params.get('conv_pool', None),\n",
    "        conv_batch_norm=final_best_params.get('conv_batch_norm', True),\n",
    "        use_attention=final_best_params.get('use_attention', False),\n",
    "    ).to(device)\n",
    "\n",
    "    # --- 8. Load the model weights for this specific split and config ---\n",
    "    # Fix: Use best_config_str directly as it already holds the experiment name or combined name.\n",
    "    model_path = f\"models/{best_config_str}/split_{split}_model.pt\"\n",
    "\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  ERROR: Model file not found at {model_path}\")\n",
    "        print(f\"  Skipping split {split + 1}.\")\n",
    "        continue\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # --- 9. Esecuzione inferenza sul test set (continue + categoriche) ---\n",
    "    split_test_preds, split_test_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for x_cont, x_cat, y in test_loader:\n",
    "            x_cont = x_cont.to(device)\n",
    "            x_cat = x_cat.to(device)\n",
    "            y = y.to(device)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                logits = model(x_cont, x_cat)\n",
    "            preds = logits.argmax(dim=1).cpu().numpy()\n",
    "            split_test_preds.append(preds)\n",
    "            split_test_targets.append(y.cpu().numpy())\n",
    "\n",
    "    split_test_preds = np.concatenate(split_test_preds)\n",
    "    split_test_targets = np.concatenate(split_test_targets)\n",
    "\n",
    "    # --- 10. Calculate and store metrics for this split ---\n",
    "    split_test_acc = accuracy_score(split_test_targets, split_test_preds)\n",
    "    split_test_prec = precision_score(split_test_targets, split_test_preds, average='weighted', zero_division=0)\n",
    "    split_test_rec = recall_score(split_test_targets, split_test_preds, average='weighted', zero_division=0)\n",
    "    split_test_f1 = f1_score(split_test_targets, split_test_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"F1 Score on test set for Split {split + 1}: {split_test_f1:.4f}\")\n",
    "\n",
    "    test_accuracies.append(split_test_acc)\n",
    "    test_precisions.append(split_test_prec)\n",
    "    test_recall_scores.append(split_test_rec)\n",
    "    test_f1_scores.append(split_test_f1)\n",
    "\n",
    "    all_test_targets.extend(split_test_targets)\n",
    "    all_test_preds.extend(split_test_preds)\n",
    "\n",
    "# --- 11. After the loop: Print mean metrics and plot confusion matrix ---\n",
    "print(\"\\nAverage metrics across all splits on the test set:\")\n",
    "print(f\"Mean Accuracy: {np.mean(test_accuracies):.4f} \\u00b1 {np.std(test_accuracies):.4f}\")\n",
    "print(f\"Mean Precision: {np.mean(test_precisions):.4f} \\u00b1 {np.std(test_precisions):.4f}\")\n",
    "print(f\"Mean Recall: {np.mean(test_recall_scores):.4f} \\u00b1 {np.std(test_recall_scores):.4f}\")\n",
    "print(f\"Mean F1 score: {np.mean(test_f1_scores):.4f} \\u00b1 {np.std(test_f1_scores):.4f}\")\n",
    "\n",
    "# Generate confusion matrix for the concatenated test sets\n",
    "cm = confusion_matrix(all_test_targets, all_test_preds)\n",
    "labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n",
    "\n",
    "# Visualise confusion matrix\n",
    "plt.figure(figsize=(8, 7))\n",
    "sns.heatmap(cm, annot=labels, fmt='',\n",
    "            cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Aggregated Confusion Matrix â€” Test Sets Across Splits')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "341580bea37494d1",
   "metadata": {
    "id": "341580bea37494d1"
   },
   "source": [
    "## **Inference on kaggle dataset**"
   ]
  },
  {
   "cell_type": "code",
   "id": "32643d925c26f316",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32643d925c26f316",
    "outputId": "94cbbb00-ffe2-4726-e95d-231a0a8442de"
   },
   "source": [
    "# --- 1. Combine fixed and best hyperparameters ---\n",
    "# 'fixed_params' and 'best_config' are loaded from the grid search cell\n",
    "final_best_params = {**fixed_params, **best_config}\n",
    "\n",
    "# Generate config string (from grid params only) to find saved model files\n",
    "# If best_config is empty (no params tuned), use EXPERIMENT_NAME directly as the key\n",
    "if not best_config:\n",
    "    best_config_str = EXPERIMENT_NAME\n",
    "else:\n",
    "    best_config_str = EXPERIMENT_NAME + \"_\".join([f\"{k}_{v}\" for k, v in best_config.items()]).replace('.', 'p')\n",
    "\n",
    "# 1) Ricava la config migliore e lo split migliore\n",
    "split_scores = [results[best_config_str].get(f\"split_{i}\", -1.0) for i in range(K)]\n",
    "best_split_idx = int(np.argmax(split_scores))\n",
    "\n",
    "print(f\"Miglior configurazione: {best_config_str}\")\n",
    "print(f\"Miglior split: {best_split_idx} con F1={split_scores[best_split_idx]:.4f}\")\n",
    "\n",
    "# 2) Istanzia il modello con gli iperparametri migliori\n",
    "best_model = RecurrentClassifier(\n",
    "    continuous_input_size=len(CONTINUOUS_COLS_REDUCED),\n",
    "    categorical_cardinalities=categorical_cardinalities,\n",
    "    embedding_dims=embedding_dims,\n",
    "    hidden_size=final_best_params['hidden_size'],\n",
    "    num_layers=final_best_params['hidden_layers'],\n",
    "    num_classes=num_classes,\n",
    "    dropout_rate=final_best_params['dropout_rate'],\n",
    "    rnn_type=final_best_params['rnn_type'],\n",
    "    bidirectional=final_best_params['bidirectional'],\n",
    "    rnn_inside_dropout=final_best_params.get('rnn_inside_dropout', 0.0),\n",
    "    use_conv=final_best_params.get('use_conv', False),\n",
    "    conv_num_filters=final_best_params.get('conv_num_filters', 64),\n",
    "    conv_kernel_size=final_best_params.get('conv_kernel_size', 5),\n",
    "    conv_num_layers=final_best_params.get('conv_num_layers', 1),\n",
    "    conv_stride=final_best_params.get('conv_stride', 1),\n",
    "    conv_pool=final_best_params.get('conv_pool', None),\n",
    "    conv_batch_norm=final_best_params.get('conv_batch_norm', True),\n",
    "    use_attention=final_best_params.get('use_attention', False),\n",
    ").to(device)\n",
    "\n",
    "# 3) Carica i pesi del modello migliore e lo scaler associato\n",
    "best_model_path = f\"models/{best_config_str}/split_{best_split_idx}_model.pt\"\n",
    "best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "best_model.eval()\n",
    "\n",
    "best_scaler_path = f\"models/{best_config_str}/split_{best_split_idx}_scaler.pkl\"\n",
    "scaler = joblib.load(best_scaler_path)\n",
    "\n",
    "print(f\"Modello caricato da {best_model_path}\")\n",
    "print(f\"Scaler caricato da {best_scaler_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9bb894d6b0be0474",
   "metadata": {
    "id": "9bb894d6b0be0474"
   },
   "source": [
    "submission_path = f\"submissions/{EXPERIMENT_NAME}_submission.csv\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "95a5215cfc279e5d",
   "metadata": {
    "id": "95a5215cfc279e5d"
   },
   "source": [
    "# 4) Funzione per creare le sequenze per l'inferenza (senza etichette)\n",
    "def build_sequences_inference(df, continuous_cols, categorical_cols, window=200, stride=200,\n",
    "                              padding_strategy='adaptive', lookback_steps=10):\n",
    "    \"\"\"\n",
    "    Build sequences for inference with adaptive padding (no labels).\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with time series data\n",
    "        continuous_cols: List of continuous feature columns\n",
    "        categorical_cols: List of categorical feature columns\n",
    "        window: Window size for sequences\n",
    "        stride: Stride for sliding window\n",
    "        padding_strategy: 'adaptive' (mean/mode), 'repeat' (repeat last), or 'zero' (zeros)\n",
    "        lookback_steps: Number of timesteps for computing padding statistics\n",
    "\n",
    "    Returns:\n",
    "        X_continuous, X_categorical, sample_owners (array of sample_index for each window)\n",
    "    \"\"\"\n",
    "\n",
    "    X_cont, X_cat, owners = [], [], []\n",
    "\n",
    "    # Pre-compute global statistics for fallback (only if adaptive)\n",
    "    if padding_strategy == 'adaptive':\n",
    "        global_cont_mean = df[continuous_cols].mean().values.astype('float32')\n",
    "        global_cat_mode = df[categorical_cols].mode().iloc[0].values.astype('int8')\n",
    "\n",
    "    for sid, g in df.groupby('sample_index'):\n",
    "        cont = g[continuous_cols].values.astype('float32')\n",
    "        cat = g[categorical_cols].values.astype('int64')\n",
    "\n",
    "        pad = (window - (len(cont) % window)) % window\n",
    "\n",
    "        if pad > 0:\n",
    "            if padding_strategy == 'adaptive':\n",
    "                # Use statistics from last timesteps\n",
    "                lookback = min(lookback_steps, len(cont))\n",
    "\n",
    "                if lookback > 0:\n",
    "                    pad_cont_value = np.mean(cont[-lookback:], axis=0, keepdims=True)\n",
    "                    pad_cat_value = np.array([\n",
    "                        np.bincount(cat[-lookback:, i]).argmax()\n",
    "                        for i in range(cat.shape[1])\n",
    "                    ]).reshape(1, -1)\n",
    "                else:\n",
    "                    pad_cont_value = global_cont_mean.reshape(1, -1)\n",
    "                    pad_cat_value = global_cat_mode.reshape(1, -1)\n",
    "\n",
    "                padding_cont = np.repeat(pad_cont_value, pad, axis=0).astype('float32')\n",
    "                padding_cat = np.repeat(pad_cat_value, pad, axis=0).astype('int64')\n",
    "\n",
    "            elif padding_strategy == 'repeat':\n",
    "                if len(cont) > 0:\n",
    "                    padding_cont = np.repeat(cont[-1:], pad, axis=0)\n",
    "                    padding_cat = np.repeat(cat[-1:], pad, axis=0)\n",
    "                else:\n",
    "                    padding_cont = np.zeros((pad, cont.shape[1]), dtype='float32')\n",
    "                    padding_cat = np.zeros((pad, cat.shape[1]), dtype='int64')\n",
    "            else:  # 'zero' or default\n",
    "                padding_cont = np.zeros((pad, cont.shape[1]), dtype='float32')\n",
    "                padding_cat = np.zeros((pad, cat.shape[1]), dtype='int64')\n",
    "\n",
    "            cont = np.concatenate([cont, padding_cont], axis=0)\n",
    "            cat = np.concatenate([cat, padding_cat], axis=0)\n",
    "\n",
    "        # Build windows\n",
    "        i = 0\n",
    "        while i + window <= len(cont):\n",
    "            X_cont.append(cont[i:i + window])\n",
    "            X_cat.append(cat[i:i + window])\n",
    "            owners.append(sid)\n",
    "            i += stride\n",
    "\n",
    "    return (np.asarray(X_cont, dtype=np.float32),\n",
    "            np.asarray(X_cat, dtype=np.int64),\n",
    "            np.asarray(owners, dtype=np.int32))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef4b4f4460e8a27d",
   "metadata": {
    "id": "ef4b4f4460e8a27d"
   },
   "source": [
    "# 5) Normalizza il kaggle test con lo scaler CORRETTO (caricato sopra), quello relativo allo split migliore\n",
    "kaggle_test_df_reduced[features_to_normalize] = scaler.transform(kaggle_test_df_reduced[features_to_normalize])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 6) Costruisci le sequenze per Kaggle test\n",
    "Xk_cont, Xk_cat, owners = build_sequences_inference(\n",
    "    kaggle_test_df_reduced,\n",
    "    continuous_cols=CONTINUOUS_COLS_REDUCED,\n",
    "    categorical_cols=CATEGORICAL_COLS_REDUCED,\n",
    "    window=final_best_params['window_size'],\n",
    "    stride=final_best_params['stride'],\n",
    "    padding_strategy=final_best_params.get('padding_strategy', 'adaptive'),\n",
    "    lookback_steps=final_best_params.get('padding_lookback_steps', 10)\n",
    ")\n",
    "\n",
    "# 7) Inference sui windows\n",
    "kaggle_ds = TensorDataset(\n",
    "    torch.from_numpy(Xk_cont).float(),\n",
    "    torch.from_numpy(Xk_cat).long()\n",
    ")\n",
    "kaggle_loader = make_loader(kaggle_ds, batch_size=final_best_params['batch_size'], shuffle=False, drop_last=False)\n",
    "\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for xb_cont, xb_cat in kaggle_loader:\n",
    "        xb_cont = xb_cont.to(device)\n",
    "        xb_cat = xb_cat.to(device)\n",
    "        logits = best_model(xb_cont, xb_cat)\n",
    "        preds = logits.argmax(dim=1).detach().cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "\n",
    "all_preds = np.concatenate(all_preds) if len(all_preds) else np.array([], dtype=np.int64)\n",
    "\n",
    "# 8) Aggrega per sample_index (maggioranza)\n",
    "preds_per_sample = {}\n",
    "for sid, p in zip(owners, all_preds):\n",
    "    preds_per_sample.setdefault(int(sid), []).append(int(p))\n",
    "\n",
    "final_idx = {sid: Counter(v).most_common(1)[0][0] for sid, v in preds_per_sample.items()}\n",
    "\n",
    "# 9) Mappa a etichette testuali e crea submission\n",
    "inv_label_map = {0: 'no_pain', 1: 'low_pain', 2: 'high_pain'}\n",
    "submission = pd.DataFrame({\n",
    "    'sample_index': list(final_idx.keys()),\n",
    "    'label': [inv_label_map[int(v)] for v in final_idx.values()]\n",
    "}).sort_values('sample_index', kind='stable')\n",
    "\n",
    "os.makedirs(\"submissions\", exist_ok=True)\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission salvata in {submission_path}\")\n",
    "\n"
   ],
   "id": "2b2fc0bab8e9b0c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bfeda8327961fe3f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
